from fastapi import FastAPI
from routes.codet5_routes import router as codet5_router
from routes.similaridade_routes import router as similaridade_router
from routes.adicionar_routes import router as adicionar_routes
from services.processar_embeddings import processar_embeddings
from services.reindex_service import reindexar_todos, reindexar_blocos
from services.faiss_io import (
    carregar_index,
    salvar_index,
    carregar_codigo_id_map,
    salvar_codigo_id_map,
)
from services.verificar_reindexacao import (
    verificar_se_precisa_reindexar,
    marcar_reindexacao_feita,
)
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
import faiss
import os
import logging

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("main")

app = FastAPI(title="Microservi√ßo de Corre√ß√£o com IA")

# üì¶ Inclus√£o das rotas
app.include_router(codet5_router, prefix="/codet5")
app.include_router(similaridade_router, prefix="/similaridade")
app.include_router(adicionar_routes)


@app.on_event("startup")
async def startup_event():
    logger.info("üöÄ Inicializando microservi√ßo...")

    try:
        model_dir = "./codet5p-220m-finetuned"
        model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)
        tokenizer = AutoTokenizer.from_pretrained(model_dir)

        app.state.model = model
        app.state.tokenizer = tokenizer

        app.state.index = carregar_index(dimension=768)
        app.state.codigo_id_map = carregar_codigo_id_map()

        logger.info(
            f"üîç √çndice FAISS cont√©m {app.state.index.ntotal} vetores carregados."
        )
        logger.info(
            f"üîç codigo_id_map cont√©m {len(app.state.codigo_id_map)} elementos carregados."
        )

        max_tokens = getattr(model.config, "n_positions", None)
        if max_tokens:
            logger.info(
                f"Modelo carregado com sucesso. Tokens m√°ximos suportados: {max_tokens}"
            )
        else:
            logger.warning(
                "Modelo carregado, mas n√∫mero de tokens m√°ximos n√£o encontrado."
            )
    except Exception as e:
        logger.error("‚ùå Erro ao carregar o modelo/tokenizer:")
        logger.exception(e)
        import sys

        sys.exit("Erro cr√≠tico: Falha ao carregar modelo/tokenizer.")

    # üîÅ Verificar se precisa reindexar ‚Äî sempre fora do try
    precisa_reindexar = verificar_se_precisa_reindexar()
    if app.state.index.ntotal == 0 or len(app.state.codigo_id_map) == 0:
        logger.warning("‚ö†Ô∏è √çndice FAISS ou c√≥digo-ID MAP vazio! For√ßando reindexa√ß√£o...")
        precisa_reindexar = True

    if precisa_reindexar:
        logger.info("üîé Iniciando processamento de embeddings e reindexa√ß√£o...")
        processar_embeddings()
        reindexar_todos(app)
        reindexar_blocos(app)

        logger.info("üíæ Salvando √≠ndice FAISS e mapa de c√≥digos...")
        salvar_index(app.state.index)
        salvar_codigo_id_map(app.state.codigo_id_map)
        marcar_reindexacao_feita()

        logger.info("‚úÖ Reindexa√ß√£o finalizada, tudo salvo e marcado.")

    if app.state.index.ntotal == 0 or len(app.state.codigo_id_map) == 0:
        logger.error(
            "‚ùå Reindexa√ß√£o conclu√≠da, mas √≠ndice FAISS ou c√≥digo-ID MAP continuam vazios!"
        )
        import sys

        sys.exit("Erro cr√≠tico: Falha na reindexa√ß√£o. Encerrando aplica√ß√£o.")
    else:
        logger.info(
            f"‚úÖ Verifica√ß√£o p√≥s-reindexa√ß√£o: √≠ndice cont√©m {app.state.index.ntotal} vetores e {len(app.state.codigo_id_map)} c√≥digos."
        )
